{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "from networkx.algorithms.community import kernighan_lin_bisection as kl_bisection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy graph - undirected, unweighted\n",
    "G = nx.gnm_random_graph(1000,2000)\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "# Toy flow graph - directed, weighted\n",
    "num_nodes = 1000\n",
    "num_edges = 2000\n",
    "flowG = nx.DiGraph()\n",
    "flowG.add_nodes_from(range(num_nodes))\n",
    "for _ in range(num_edges):\n",
    "    source, target = np.random.choice(range(num_nodes), size=2, replace=False)\n",
    "    flowG.add_edge(source, target, capacity=np.random.uniform(0.0, 20.0))\n",
    "flowG.remove_nodes_from(list(nx.isolates(flowG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mincut_maxflow(G, num_splits):\n",
    "    partitions = []\n",
    "    \n",
    "    def split(G, i):\n",
    "        if i == 0 or G.number_of_nodes() <= 1:\n",
    "            partitions.append(G)\n",
    "        else:\n",
    "            source = np.random.choice([node for node in G.nodes if G.in_degree(node)==0])\n",
    "            sink = np.random.choice([node for node in G.nodes if G.out_degree(node)==0])\n",
    "            while source == sink:\n",
    "                sink = np.random.choice([node for node in G.nodes if G.out_degree(node==0)])\n",
    "            part_A, part_B = nx.minimum_cut(G, source, sink)[1]\n",
    "            A = split(G.subgraph(part_A), i-1)\n",
    "            B = split(G.subgraph(part_B), i-1)\n",
    "    \n",
    "    split(G, num_splits)\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mKL\u001b[39m(G, num_splits, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mG\u001b[49m\u001b[38;5;241m.\u001b[39mnodes)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      2\u001b[0m     partitions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpartition\u001b[39m(G, i):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "def KL(G, num_splits, max_iter=len(G.nodes)//2):\n",
    "    partitions = []\n",
    "    \n",
    "    def partition(G, i):\n",
    "        if i == 0:\n",
    "            partitions.append(G)\n",
    "        else:\n",
    "            part_A, part_B = kl_bisection(G, max_iter=max_iter)\n",
    "            A = partition(G.subgraph(part_A), i - 1)\n",
    "            B = partition(G.subgraph(part_B), i - 1)\n",
    "\n",
    "    partition(G, num_splits)\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_initial_gain(G, node, partition):\n",
    "    internal, external = 0, 0\n",
    "    for neighbor in G[node]:\n",
    "        if neighbor in partition:\n",
    "            internal += G[node][neighbor].get('weight', 1)\n",
    "        else:\n",
    "            external += G[node][neighbor].get('weight', 1)\n",
    "    return external - internal\n",
    "\n",
    "def update_gains_and_queue(G, node, partition_a, partition_b, heap, node_to_heap):\n",
    "    for neighbor in G[node]:\n",
    "        if neighbor not in node_to_heap:\n",
    "            continue\n",
    "        if neighbor in partition_a:\n",
    "            new_gain = calculate_initial_gain(G, neighbor, partition_a)\n",
    "        else:\n",
    "            new_gain = calculate_initial_gain(G, neighbor, partition_b)\n",
    "        \n",
    "        heap_entry = node_to_heap[neighbor]\n",
    "        heap_entry[0] = -new_gain  # Negate for max-heap\n",
    "        heapq.heapify(heap)  # Re-heapify\n",
    "\n",
    "def is_balanced(partition_a, partition_b, max_imbalance):\n",
    "    size_a = len(partition_a)\n",
    "    size_b = len(partition_b)\n",
    "    return abs(size_a - size_b) <= max_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_partition(G, max_passes=10, max_imbalance=1):\n",
    "    nodes = list(G.nodes())  # Convert Nodes to a list\n",
    "    random.shuffle(nodes)  # Shuffle to ensure random partitioning\n",
    "    \n",
    "    partition_a, partition_b = set(nodes[:len(G)//2]), set(nodes[len(G)//2:])\n",
    "    heap = []\n",
    "    node_to_heap = {}\n",
    "\n",
    "    # Initialize gains and heap\n",
    "    for node in G:\n",
    "        gain = calculate_initial_gain(G, node, partition_a if node in partition_a else partition_b)\n",
    "        heap_entry = [-gain, node]  # Negate gain for max-heap\n",
    "        heapq.heappush(heap, heap_entry)\n",
    "        node_to_heap[node] = heap_entry\n",
    "\n",
    "    for _ in range(max_passes):\n",
    "        if not heap:\n",
    "            break\n",
    "\n",
    "        # Find a suitable node to move\n",
    "        while heap:\n",
    "            gain, node = heapq.heappop(heap)\n",
    "            gain = -gain  # Correct the negated gain\n",
    "\n",
    "            if node in partition_a and is_balanced(partition_a - {node}, partition_b | {node}, max_imbalance):\n",
    "                partition_a.remove(node)\n",
    "                partition_b.add(node)\n",
    "                break\n",
    "            elif node in partition_b and is_balanced(partition_a | {node}, partition_b - {node}, max_imbalance):\n",
    "                partition_b.remove(node)\n",
    "                partition_a.add(node)\n",
    "                break\n",
    "\n",
    "        if not heap:\n",
    "            # No suitable node found\n",
    "            break\n",
    "\n",
    "        # Lock this node\n",
    "        del node_to_heap[node]\n",
    "\n",
    "        # Update gains of neighbors\n",
    "        update_gains_and_queue(G, node, partition_a, partition_b, heap, node_to_heap)\n",
    "\n",
    "    return partition_a, partition_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subgraphs(G, partition_a, partition_b):\n",
    "    # Create subgraphs for each partition\n",
    "    subgraph_a = G.subgraph(partition_a).copy()\n",
    "    subgraph_b = G.subgraph(partition_b).copy()\n",
    "\n",
    "    return subgraph_a, subgraph_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_fm(G, subgraphs, k, max_imbalance):\n",
    "    \n",
    "    if k == 0:\n",
    "        subgraphs.append(G)\n",
    "        return G\n",
    "    \n",
    "    p_a, p_b = fm_partition(G, k, max_imbalance)\n",
    "    subgraph_a, subgraph_b = create_subgraphs(G, p_a, p_b)\n",
    "    \n",
    "    multiple_fm(subgraph_a, subgraphs, k - 1, max_imbalance)\n",
    "    multiple_fm(subgraph_b, subgraphs, k - 1, max_imbalance)\n",
    "    \n",
    "    return subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = np.load('../data/xbar/1/xbar_connectivity.npz')\n",
    "A = coo_matrix((conn['data'], (conn['row'], conn['col'])), shape=conn['shape'])\n",
    "A = A.__mul__(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_tensors = from_scipy_sparse_matrix(A)\n",
    "edge_weights = edge_tensors[1]\n",
    "edge_list = [(u.item(),v.item(), weight) for u, v, weight in zip(edge_tensors[0][0], edge_tensors[0][1], edge_weights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_weighted_edges_from(edge_list)\n",
    "# G = nx.gnm_random_graph(1000, 2000)\n",
    "dag = nx.graph.deepcopy(G)\n",
    "subgraphs = []\n",
    "subgraph_partitions = 3\n",
    "max_imbalance = 10\n",
    "partition_output = multiple_fm(dag, [], subgraph_partitions, max_imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<networkx.classes.digraph.DiGraph at 0x22b74a97dd0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x22b74119290>,\n",
       " <networkx.classes.digraph.DiGraph at 0x22b76323d90>,\n",
       " <networkx.classes.digraph.DiGraph at 0x22b73ec4590>,\n",
       " <networkx.classes.digraph.DiGraph at 0x22b551328d0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x22b751a0350>,\n",
       " <networkx.classes.digraph.DiGraph at 0x22b75cfbed0>,\n",
       " <networkx.classes.digraph.DiGraph at 0x22b75cfbe50>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 494, 2468\n",
      " 496, 2842\n",
      " 494, 2716\n",
      " 493, 2443\n",
      " 493, 2659\n",
      " 496, 2750\n",
      " 494, 2634\n",
      " 492, 2688\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(partition_output):\n",
    "    print(f' {p.number_of_nodes()}, {p.number_of_edges()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_dag(original_graph, reconstructed_dag, subgraph):\n",
    "    # Add nodes and edges from subgraph\n",
    "    for node in subgraph.nodes():\n",
    "        reconstructed_dag.add_node(node)\n",
    "    reconstructed_dag.add_edges_from(subgraph.edges())\n",
    "\n",
    "    # Add inter-partition edges from original graph\n",
    "    for u, v in original_graph.edges():\n",
    "        if u in subgraph or v in subgraph:\n",
    "            reconstructed_dag.add_edge(u, v, inter_partition=True)\n",
    "\n",
    "    return reconstructed_dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resconstructed_dag = nx.DiGraph()\n",
    "# for i in range(len(partition_output)):\n",
    "#     reconstructed_dag = reconstruct_dag(G, resconstructed_dag, partition_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nodes with data\n",
    "nodes_data = list(partition_output[0].nodes(data=True))\n",
    "\n",
    "# Get edges with data\n",
    "edges_data = list(partition_output[0].edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get me the value of edge_weight from edges_data\n",
    "edge_weights = [edge[2]['weight'] for edge in edges_data]\n",
    "edges_data\n",
    "\n",
    "len(nodes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141472"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
