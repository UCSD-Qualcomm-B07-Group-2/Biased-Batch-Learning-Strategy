{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9561a85-6d1b-405f-845f-abba6dd676a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn.conv import GATConv\n",
    "from torch.nn import Linear, ModuleList, Dropout, BatchNorm1d\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torch_geometric.utils import subgraph\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm as tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454bd5c4-00fc-45af-8c10-955f2924a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/xbar/1/xbar.json.gz','rb') as f:\n",
    "    design = json.loads(f.read().decode('utf-8'))\n",
    "\n",
    "instances = pd.DataFrame(design['instances'])\n",
    "nets = pd.DataFrame(design['nets'])\n",
    "\n",
    "conn=np.load('../data/xbar/1/xbar_connectivity.npz')\n",
    "A = coo_matrix((conn['data'], (conn['row'], conn['col'])), shape=conn['shape'])\n",
    "A = A.__mul__(A.T)\n",
    "def buildBST(array,start=0,finish=-1):\n",
    "    if finish<0:\n",
    "        finish = len(array)\n",
    "    mid = (start + finish) // 2\n",
    "    if mid-start==1:\n",
    "        ltl=start\n",
    "    else:\n",
    "        ltl=buildBST(array,start,mid)\n",
    "    \n",
    "    if finish-mid==1:\n",
    "        gtl=mid\n",
    "    else:\n",
    "        gtl=buildBST(array,mid,finish)\n",
    "        \n",
    "    return((array[mid],ltl,gtl))\n",
    "\n",
    "congestion_data = np.load('../data/xbar/1/xbar_congestion.npz')\n",
    "xbst=buildBST(congestion_data['xBoundaryList'])\n",
    "ybst=buildBST(congestion_data['yBoundaryList'])\n",
    "demand = np.zeros(shape = [instances.shape[0],])\n",
    "\n",
    "def getGRCIndex(x,y,xbst,ybst):\n",
    "    while (type(xbst)==tuple):\n",
    "        if x < xbst[0]:\n",
    "            xbst=xbst[1]\n",
    "        else:\n",
    "            xbst=xbst[2]\n",
    "            \n",
    "    while (type(ybst)==tuple):\n",
    "        if y < ybst[0]:\n",
    "            ybst=ybst[1]\n",
    "        else:\n",
    "            ybst=ybst[2]\n",
    "            \n",
    "    return ybst, xbst\n",
    "\n",
    "\n",
    "for k in range(instances.shape[0]):\n",
    "    # print(k)\n",
    "    xloc = instances.iloc[k]['xloc']; yloc = instances.iloc[k]['yloc']\n",
    "    i,j=getGRCIndex(xloc,yloc,xbst,ybst)\n",
    "    d = 0 \n",
    "    for l in list(congestion_data['layerList']): \n",
    "        lyr=list(congestion_data['layerList']).index(l)\n",
    "        d += congestion_data['demand'][lyr][i][j]\n",
    "    demand[k] = d\n",
    "        \n",
    "instances['routing_demand'] = demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f67a68e1-6443-47ff-9253-5726ca2df36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # for replication\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X = torch.tensor(instances[['xloc', 'yloc', 'cell', 'orient']].values)\n",
    "y = torch.tensor(instances['routing_demand'].values)\n",
    "ei = from_scipy_sparse_matrix(A)\n",
    "edge_index = ei[0]\n",
    "data = Data(x=X, edge_index=edge_index, y=y)\n",
    "split = RandomNodeSplit(num_splits=1, num_val=0.0, num_test=0.3)\n",
    "split_data = split(data)\n",
    "train_mask = split_data.train_mask\n",
    "test_mask = split_data.test_mask\n",
    "\n",
    "train = torch.argwhere(split_data.train_mask).reshape(-1)\n",
    "test = torch.argwhere(split_data.test_mask).reshape(-1)\n",
    "train_mapping = {a.item():b for a,b in zip(train, range(train.shape[0]))}\n",
    "test_mapping = {a.item():b for a,b in zip(test, range(test.shape[0]))}\n",
    "train_subgraph = subgraph(train_mask, data.edge_index, relabel_nodes=True, num_nodes=data.num_nodes)\n",
    "test_subgraph = subgraph(test_mask, data.edge_index, relabel_nodes=True, num_nodes=data.num_nodes)\n",
    "final_train = Data(x=data.x[train_mask], edge_index=train_subgraph[0], y=data.y[train_mask])\n",
    "final_test = Data(x=data.x[test_mask], edge_index=test_subgraph[0], y=data.y[test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7d9b3f-5ad2-4287-91e7-062a68c95034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 5.8637880269814495\n",
      "R-squared Score: 0.715635348801225\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(final_train.x.numpy(), final_train.y.numpy().ravel())\n",
    "predictions = rf_regressor.predict(final_test.x.numpy())\n",
    "mse = mean_squared_error(final_test.y.numpy().ravel(), predictions)\n",
    "r2 = r2_score(final_test.y.numpy().ravel(), predictions)\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'R-squared Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa74ade1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>xloc</th>\n",
       "      <th>yloc</th>\n",
       "      <th>cell</th>\n",
       "      <th>orient</th>\n",
       "      <th>routing_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clk_gate_out_reg/latch</td>\n",
       "      <td>0</td>\n",
       "      <td>41984</td>\n",
       "      <td>44544</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clk_gate_out_reg_0/latch</td>\n",
       "      <td>1</td>\n",
       "      <td>41984</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clk_gate_out_reg_1/latch</td>\n",
       "      <td>2</td>\n",
       "      <td>44160</td>\n",
       "      <td>44544</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clk_gate_out_reg_2/latch</td>\n",
       "      <td>3</td>\n",
       "      <td>44160</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clk_gate_out_reg_3/latch</td>\n",
       "      <td>4</td>\n",
       "      <td>46336</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>U4123</td>\n",
       "      <td>3947</td>\n",
       "      <td>21888</td>\n",
       "      <td>53760</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>U4125</td>\n",
       "      <td>3948</td>\n",
       "      <td>33664</td>\n",
       "      <td>66048</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>U4128</td>\n",
       "      <td>3949</td>\n",
       "      <td>23296</td>\n",
       "      <td>66048</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>ZCTSBUF_205_132</td>\n",
       "      <td>3950</td>\n",
       "      <td>40576</td>\n",
       "      <td>44544</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>ZCTSBUF_466_133</td>\n",
       "      <td>3951</td>\n",
       "      <td>46848</td>\n",
       "      <td>44544</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3952 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name    id   xloc   yloc  cell  orient  \\\n",
       "0       clk_gate_out_reg/latch     0  41984  44544    23       0   \n",
       "1     clk_gate_out_reg_0/latch     1  41984  47616    23       6   \n",
       "2     clk_gate_out_reg_1/latch     2  44160  44544    23       0   \n",
       "3     clk_gate_out_reg_2/latch     3  44160  47616    23       0   \n",
       "4     clk_gate_out_reg_3/latch     4  46336  47616    23       0   \n",
       "...                        ...   ...    ...    ...   ...     ...   \n",
       "3947                     U4123  3947  21888  53760    42       4   \n",
       "3948                     U4125  3948  33664  66048    42       0   \n",
       "3949                     U4128  3949  23296  66048    34       0   \n",
       "3950           ZCTSBUF_205_132  3950  40576  44544    11       0   \n",
       "3951           ZCTSBUF_466_133  3951  46848  44544    11       6   \n",
       "\n",
       "      routing_demand  \n",
       "0               20.0  \n",
       "1               23.0  \n",
       "2               23.0  \n",
       "3               22.0  \n",
       "4               21.0  \n",
       "...              ...  \n",
       "3947            31.0  \n",
       "3948            30.0  \n",
       "3949            27.0  \n",
       "3950            28.0  \n",
       "3951            23.0  \n",
       "\n",
       "[3952 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de5c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRC_widths = instances.groupby('cell')['xloc'].max() - instances.groupby('cell')['xloc'].min()\n",
    "GRC_heights = instances.groupby('cell')['yloc'].max() - instances.groupby('cell')['yloc'].min()\n",
    "GRC_area = GRC_widths * GRC_heights\n",
    "GRC_area = GRC_area.replace(0, np.nan)  # Replace 0 areas with NaN\n",
    "pin_density = instances.groupby('cell')['id'].count() / GRC_area\n",
    "pin_density = pin_density.fillna(0)\n",
    "pin_df = pd.DataFrame(pin_density.rename('pin_density')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f4fff0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instances = instances.merge(pin_df, how='left', on='cell')\n",
    "instances['degree'] = np.array(A.sum(axis=1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a33d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>xloc</th>\n",
       "      <th>yloc</th>\n",
       "      <th>cell</th>\n",
       "      <th>orient</th>\n",
       "      <th>routing_demand</th>\n",
       "      <th>pin_density</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clk_gate_out_reg/latch</td>\n",
       "      <td>0</td>\n",
       "      <td>41984</td>\n",
       "      <td>44544</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clk_gate_out_reg_0/latch</td>\n",
       "      <td>1</td>\n",
       "      <td>41984</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clk_gate_out_reg_1/latch</td>\n",
       "      <td>2</td>\n",
       "      <td>44160</td>\n",
       "      <td>44544</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clk_gate_out_reg_2/latch</td>\n",
       "      <td>3</td>\n",
       "      <td>44160</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clk_gate_out_reg_3/latch</td>\n",
       "      <td>4</td>\n",
       "      <td>46336</td>\n",
       "      <td>47616</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>U4123</td>\n",
       "      <td>3947</td>\n",
       "      <td>21888</td>\n",
       "      <td>53760</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.247994e-08</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>U4125</td>\n",
       "      <td>3948</td>\n",
       "      <td>33664</td>\n",
       "      <td>66048</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.247994e-08</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>U4128</td>\n",
       "      <td>3949</td>\n",
       "      <td>23296</td>\n",
       "      <td>66048</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.496090e-08</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>ZCTSBUF_205_132</td>\n",
       "      <td>3950</td>\n",
       "      <td>40576</td>\n",
       "      <td>44544</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>ZCTSBUF_466_133</td>\n",
       "      <td>3951</td>\n",
       "      <td>46848</td>\n",
       "      <td>44544</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3952 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name    id   xloc   yloc  cell  orient  \\\n",
       "0       clk_gate_out_reg/latch     0  41984  44544    23       0   \n",
       "1     clk_gate_out_reg_0/latch     1  41984  47616    23       6   \n",
       "2     clk_gate_out_reg_1/latch     2  44160  44544    23       0   \n",
       "3     clk_gate_out_reg_2/latch     3  44160  47616    23       0   \n",
       "4     clk_gate_out_reg_3/latch     4  46336  47616    23       0   \n",
       "...                        ...   ...    ...    ...   ...     ...   \n",
       "3947                     U4123  3947  21888  53760    42       4   \n",
       "3948                     U4125  3948  33664  66048    42       0   \n",
       "3949                     U4128  3949  23296  66048    34       0   \n",
       "3950           ZCTSBUF_205_132  3950  40576  44544    11       0   \n",
       "3951           ZCTSBUF_466_133  3951  46848  44544    11       6   \n",
       "\n",
       "      routing_demand   pin_density  degree  \n",
       "0               20.0  2.991919e-07     681  \n",
       "1               23.0  2.991919e-07     681  \n",
       "2               23.0  2.991919e-07     681  \n",
       "3               22.0  2.991919e-07     681  \n",
       "4               21.0  2.991919e-07     681  \n",
       "...              ...           ...     ...  \n",
       "3947            31.0  8.247994e-08     276  \n",
       "3948            30.0  8.247994e-08     276  \n",
       "3949            27.0  5.496090e-08     180  \n",
       "3950            28.0  0.000000e+00     139  \n",
       "3951            23.0  0.000000e+00      31  \n",
       "\n",
       "[3952 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb9a44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "transformed = ohe.fit_transform(instances[['cell']])\n",
    "ohe_df = pd.DataFrame.sparse.from_spmatrix(transformed)\n",
    "ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bf0274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xloc</th>\n",
       "      <th>yloc</th>\n",
       "      <th>orient</th>\n",
       "      <th>routing_demand</th>\n",
       "      <th>pin_density</th>\n",
       "      <th>degree</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41984</td>\n",
       "      <td>44544</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41984</td>\n",
       "      <td>47616</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44160</td>\n",
       "      <td>44544</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44160</td>\n",
       "      <td>47616</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46336</td>\n",
       "      <td>47616</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.991919e-07</td>\n",
       "      <td>681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>21888</td>\n",
       "      <td>53760</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.247994e-08</td>\n",
       "      <td>276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>33664</td>\n",
       "      <td>66048</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.247994e-08</td>\n",
       "      <td>276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>23296</td>\n",
       "      <td>66048</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.496090e-08</td>\n",
       "      <td>180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>40576</td>\n",
       "      <td>44544</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>46848</td>\n",
       "      <td>44544</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3952 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xloc   yloc  orient  routing_demand   pin_density  degree    0    1  \\\n",
       "0     41984  44544       0            20.0  2.991919e-07     681  0.0  0.0   \n",
       "1     41984  47616       6            23.0  2.991919e-07     681  0.0  0.0   \n",
       "2     44160  44544       0            23.0  2.991919e-07     681  0.0  0.0   \n",
       "3     44160  47616       0            22.0  2.991919e-07     681  0.0  0.0   \n",
       "4     46336  47616       0            21.0  2.991919e-07     681  0.0  0.0   \n",
       "...     ...    ...     ...             ...           ...     ...  ...  ...   \n",
       "3947  21888  53760       4            31.0  8.247994e-08     276  0.0  0.0   \n",
       "3948  33664  66048       0            30.0  8.247994e-08     276  0.0  0.0   \n",
       "3949  23296  66048       0            27.0  5.496090e-08     180  0.0  0.0   \n",
       "3950  40576  44544       0            28.0  0.000000e+00     139  0.0  0.0   \n",
       "3951  46848  44544       6            23.0  0.000000e+00      31  0.0  0.0   \n",
       "\n",
       "        2    3    4    5    6    7    8    9   10   11   12  \n",
       "0     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "3947  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3948  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3949  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3950  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3951  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3952 rows x 19 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances = instances.merge(ohe_df, left_index=True, right_index=True).drop(columns=['cell', 'name', 'id'])\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60a31f97-67e5-419a-8b18-462bca64eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(42) # for replication\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X = torch.tensor(instances.drop('routing_demand', axis=1).values, dtype=torch.float)\n",
    "y = torch.tensor(instances['routing_demand'].values, dtype=torch.float)\n",
    "ei = from_scipy_sparse_matrix(A)\n",
    "edge_index = ei[0].to(dtype=torch.long) \n",
    "data = Data(x=X, edge_index=edge_index, y=y)\n",
    "split = RandomNodeSplit(num_splits=1, num_val=0.0, num_test=0.3)\n",
    "split_data = split(data)\n",
    "train_mask = split_data.train_mask\n",
    "test_mask = split_data.test_mask\n",
    "\n",
    "train = torch.argwhere(split_data.train_mask).reshape(-1)\n",
    "test = torch.argwhere(split_data.test_mask).reshape(-1)\n",
    "train_mapping = {a.item():b for a,b in zip(train, range(train.shape[0]))}\n",
    "test_mapping = {a.item():b for a,b in zip(test, range(test.shape[0]))}\n",
    "train_subgraph = subgraph(train_mask, data.edge_index, relabel_nodes=True, num_nodes=data.num_nodes)\n",
    "test_subgraph = subgraph(test_mask, data.edge_index, relabel_nodes=True, num_nodes=data.num_nodes)\n",
    "final_train = Data(x=data.x[train_mask], edge_index=train_subgraph[0], y=data.y[train_mask]).to(device).to(device)\n",
    "final_test = Data(x=data.x[test_mask], edge_index=test_subgraph[0], y=data.y[test_mask]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bf81653-ff63-4677-a948-6e8102b9bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_hidden_layers, hidden_channels, dropout_rate=0.5, activation_function='relu'):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn = GATConv(num_features, hidden_channels)\n",
    "        self.hidden_layers = ModuleList([])\n",
    "        self.batch_norms =  ModuleList([])\n",
    "        for _ in range(num_hidden_layers):\n",
    "            self.hidden_layers.append(GATConv(hidden_channels, hidden_channels))\n",
    "            self.batch_norms.append(BatchNorm1d(hidden_channels))\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.out = Linear(hidden_channels, 1)\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        if self.activation_function == 'relu':\n",
    "            activation = F.relu\n",
    "        elif self.activation_function == 'leaky_relu':\n",
    "            activation = F.leaky_relu\n",
    "        elif self.activation_function == 'elu':\n",
    "            activation = F.elu\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        x = activation(self.gcn(x, edge_index))\n",
    "        for layer, norm in zip(self.hidden_layers, self.batch_norms):\n",
    "            x = self.dropout(x)\n",
    "            x = layer(x, edge_index)\n",
    "            x = norm(x)\n",
    "            x = activation(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0d8233a-0aaa-4cd1-a9c1-dc9a5eee746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, test_data, optimizer_choice='adam', lr=0.01, epochs=200):\n",
    "    data = data.to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    elif optimizer_choice == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer\")\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        z = model(data)\n",
    "        z = z.to(device)\n",
    "        loss = criterion(z.squeeze(), data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch:>3} | Loss: {loss:.2f}')\n",
    "            # print(test_mse(model,test_data))\n",
    "\n",
    "def test_mse_with_errors(model, test_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_data = test_data.to(device)\n",
    "        predictions = model(test_data)\n",
    "        errors = (predictions.squeeze() - test_data.y.float()).cpu().numpy()  # Calculate individual errors\n",
    "        mse = F.mse_loss(predictions.squeeze(), test_data.y.float()).item()  # Calculate MSE\n",
    "\n",
    "    return mse, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2af675a4-132d-4242-a7b6-238988368acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one_layer_model = GCN(num_features=final_train.x.shape[1], num_hidden_layers=0, hidden_channels=768).to(device)\n",
    "# train(one_layer_model, final_train, final_test)\n",
    "# print(test_mse(one_layer_model, final_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e972476f-131f-4945-bd9e-231c61e69d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Loss: 665.66\n",
      "Epoch  10 | Loss: 550.36\n",
      "Epoch  20 | Loss: 445.20\n",
      "Epoch  30 | Loss: 361.20\n",
      "Epoch  40 | Loss: 275.97\n",
      "Epoch  50 | Loss: 199.16\n",
      "Epoch  60 | Loss: 213.26\n",
      "Epoch  70 | Loss: 155.04\n",
      "Epoch  80 | Loss: 122.77\n",
      "Epoch  90 | Loss: 102.19\n",
      "Epoch 100 | Loss: 79.50\n",
      "Epoch 110 | Loss: 69.07\n",
      "Epoch 120 | Loss: 62.14\n",
      "Epoch 130 | Loss: 56.22\n",
      "Epoch 140 | Loss: 62.13\n",
      "Epoch 150 | Loss: 45.43\n",
      "Epoch 160 | Loss: 48.22\n",
      "Epoch 170 | Loss: 44.90\n",
      "Epoch 180 | Loss: 40.89\n",
      "Epoch 190 | Loss: 39.78\n",
      "Epoch 200 | Loss: 44.41\n",
      "Epoch 210 | Loss: 40.99\n",
      "Epoch 220 | Loss: 41.97\n",
      "Epoch 230 | Loss: 40.44\n",
      "Epoch 240 | Loss: 40.00\n",
      "Epoch 250 | Loss: 40.69\n",
      "Epoch 260 | Loss: 38.66\n",
      "Epoch 270 | Loss: 33.35\n",
      "Epoch 280 | Loss: 38.02\n",
      "Epoch 290 | Loss: 33.10\n",
      "Epoch 300 | Loss: 35.40\n",
      "Epoch 310 | Loss: 30.56\n",
      "Epoch 320 | Loss: 37.88\n",
      "Epoch 330 | Loss: 32.57\n",
      "Epoch 340 | Loss: 34.20\n",
      "Epoch 350 | Loss: 33.56\n",
      "Epoch 360 | Loss: 32.21\n",
      "Epoch 370 | Loss: 29.56\n",
      "Epoch 380 | Loss: 33.37\n",
      "Epoch 390 | Loss: 32.25\n",
      "Epoch 400 | Loss: 33.07\n",
      "Epoch 410 | Loss: 32.55\n",
      "Epoch 420 | Loss: 29.21\n",
      "Epoch 430 | Loss: 33.44\n",
      "Epoch 440 | Loss: 31.65\n",
      "Epoch 450 | Loss: 28.65\n",
      "Epoch 460 | Loss: 30.05\n",
      "Epoch 470 | Loss: 31.58\n",
      "Epoch 480 | Loss: 44.48\n",
      "Epoch 490 | Loss: 30.01\n",
      "Test MSE: 124.32337951660156\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "two_layer_model = GCN(num_features=final_train.x.shape[1], \n",
    "            num_hidden_layers=3,  # Increase model complexity carefully\n",
    "            hidden_channels=1200, \n",
    "            dropout_rate=0.45,  # Adjust dropout rate\n",
    "            activation_function='relu').to(device)\n",
    "train(two_layer_model, final_train, final_test,optimizer_choice='adam', lr=0.001 / 2, epochs=500)\n",
    "mse, errors = test_mse_with_errors(two_layer_model, final_test)\n",
    "print(f\"Test MSE: {mse}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(errors, bins=50, alpha=0.7)\n",
    "plt.title(\"Distribution of Prediction Errors\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(np.abs(errors), bins=50, alpha=0.7)\n",
    "plt.title(\"Distribution of Absolute Prediction Errors\")\n",
    "plt.xlabel(\"Absolute Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "216d0445-905a-42d2-a2ab-54cdd4cebf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0bbf317f-d2ed-436b-ac6b-b9ad6264464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 33216292.0\n",
      "1936690.125\n",
      "Epoch 10, Loss: 2750961.0\n",
      "285544.625\n",
      "Epoch 20, Loss: 2017623.25\n",
      "2067298.5\n",
      "Epoch 30, Loss: 33553.55078125\n",
      "217070.984375\n",
      "Epoch 40, Loss: 208577.015625\n",
      "58813.1953125\n",
      "Epoch 50, Loss: 113525.8515625\n",
      "90008.609375\n",
      "Epoch 60, Loss: 29683.44140625\n",
      "38986.09765625\n",
      "Epoch 70, Loss: 10110.3818359375\n",
      "15114.419921875\n",
      "Epoch 80, Loss: 4906.6689453125\n",
      "7038.6015625\n",
      "Epoch 90, Loss: 3409.84033203125\n",
      "3865.6953125\n",
      "Epoch 100, Loss: 2350.976318359375\n",
      "2233.921142578125\n",
      "Epoch 110, Loss: 1616.89404296875\n",
      "1481.134521484375\n",
      "Epoch 120, Loss: 1170.3365478515625\n",
      "1199.4595947265625\n",
      "Epoch 130, Loss: 977.71630859375\n",
      "1038.6510009765625\n",
      "Epoch 140, Loss: 845.7334594726562\n",
      "875.941650390625\n",
      "Epoch 150, Loss: 733.633056640625\n",
      "761.0613403320312\n",
      "Epoch 160, Loss: 656.839599609375\n",
      "680.7344360351562\n",
      "Epoch 170, Loss: 593.1763916015625\n",
      "616.171142578125\n",
      "Epoch 180, Loss: 540.6138916015625\n",
      "562.6934204101562\n",
      "Epoch 190, Loss: 496.363525390625\n",
      "516.8653564453125\n",
      "Epoch 200, Loss: 458.62640380859375\n",
      "478.35076904296875\n",
      "Epoch 210, Loss: 425.7164611816406\n",
      "445.4825134277344\n",
      "Epoch 220, Loss: 396.9002990722656\n",
      "416.9770812988281\n",
      "Epoch 230, Loss: 371.5602722167969\n",
      "392.6037292480469\n",
      "Epoch 240, Loss: 349.621826171875\n",
      "371.5599365234375\n",
      "Epoch 250, Loss: 330.5746765136719\n",
      "352.53173828125\n",
      "Epoch 260, Loss: 314.22137451171875\n",
      "335.791015625\n",
      "Epoch 270, Loss: 300.2200012207031\n",
      "321.4006652832031\n",
      "Epoch 280, Loss: 288.02850341796875\n",
      "308.8924865722656\n",
      "Epoch 290, Loss: 277.2902526855469\n",
      "297.8502502441406\n",
      "Epoch 300, Loss: 267.88372802734375\n",
      "287.9638671875\n",
      "Epoch 310, Loss: 259.5908508300781\n",
      "278.79754638671875\n",
      "Epoch 320, Loss: 252.2501678466797\n",
      "270.4368896484375\n",
      "Epoch 330, Loss: 245.7421875\n",
      "262.9193420410156\n",
      "Epoch 340, Loss: 239.84164428710938\n",
      "256.0404968261719\n",
      "Epoch 350, Loss: 234.48175048828125\n",
      "249.6926727294922\n",
      "Epoch 360, Loss: 229.6278533935547\n",
      "243.87879943847656\n",
      "Epoch 370, Loss: 225.25125122070312\n",
      "238.4857177734375\n",
      "Epoch 380, Loss: 221.2315673828125\n",
      "233.4932098388672\n",
      "Epoch 390, Loss: 217.43426513671875\n",
      "228.82225036621094\n",
      "Epoch 400, Loss: 213.85919189453125\n",
      "224.4959259033203\n",
      "Epoch 410, Loss: 210.4713134765625\n",
      "220.40333557128906\n",
      "Epoch 420, Loss: 207.2409210205078\n",
      "216.4697723388672\n",
      "Epoch 430, Loss: 204.12368774414062\n",
      "212.72015380859375\n",
      "Epoch 440, Loss: 201.11032104492188\n",
      "209.10916137695312\n",
      "Epoch 450, Loss: 198.20089721679688\n",
      "205.66184997558594\n",
      "Epoch 460, Loss: 195.4270477294922\n",
      "202.35205078125\n",
      "Epoch 470, Loss: 192.76084899902344\n",
      "199.15545654296875\n",
      "Epoch 480, Loss: 190.18077087402344\n",
      "196.06951904296875\n",
      "Epoch 490, Loss: 187.67181396484375\n",
      "193.09432983398438\n",
      "Epoch 500, Loss: 185.23109436035156\n",
      "190.2329864501953\n",
      "Epoch 510, Loss: 182.853271484375\n",
      "187.4567413330078\n",
      "Epoch 520, Loss: 180.54354858398438\n",
      "184.78335571289062\n",
      "Epoch 530, Loss: 178.29563903808594\n",
      "182.19757080078125\n",
      "Epoch 540, Loss: 176.12115478515625\n",
      "179.71258544921875\n",
      "Epoch 550, Loss: 174.010009765625\n",
      "177.3261260986328\n",
      "Epoch 560, Loss: 171.95864868164062\n",
      "175.01318359375\n",
      "Epoch 570, Loss: 169.97178649902344\n",
      "172.77891540527344\n",
      "Epoch 580, Loss: 168.0647430419922\n",
      "170.6449432373047\n",
      "Epoch 590, Loss: 166.22714233398438\n",
      "168.59376525878906\n",
      "Epoch 600, Loss: 164.4463348388672\n",
      "166.5992431640625\n",
      "Epoch 610, Loss: 162.72952270507812\n",
      "164.66305541992188\n",
      "Epoch 620, Loss: 161.05953979492188\n",
      "162.78025817871094\n",
      "Epoch 630, Loss: 159.46141052246094\n",
      "160.9869842529297\n",
      "Epoch 640, Loss: 157.93885803222656\n",
      "159.27487182617188\n",
      "Epoch 650, Loss: 156.45802307128906\n",
      "157.6181182861328\n",
      "Epoch 660, Loss: 155.0326690673828\n",
      "156.01025390625\n",
      "Epoch 670, Loss: 153.65780639648438\n",
      "154.46290588378906\n",
      "Epoch 680, Loss: 152.32122802734375\n",
      "152.96958923339844\n",
      "Epoch 690, Loss: 151.01943969726562\n",
      "151.51649475097656\n",
      "Epoch 700, Loss: 149.76663208007812\n",
      "150.1232147216797\n",
      "Epoch 710, Loss: 148.5758056640625\n",
      "148.81251525878906\n",
      "Epoch 720, Loss: 147.42227172851562\n",
      "147.53952026367188\n",
      "Epoch 730, Loss: 146.29620361328125\n",
      "146.2947998046875\n",
      "Epoch 740, Loss: 145.2048797607422\n",
      "145.09463500976562\n",
      "Epoch 750, Loss: 144.16043090820312\n",
      "143.94015502929688\n",
      "Epoch 760, Loss: 143.16143798828125\n",
      "142.8345947265625\n",
      "Epoch 770, Loss: 142.18829345703125\n",
      "141.7634735107422\n",
      "Epoch 780, Loss: 141.23814392089844\n",
      "140.73895263671875\n",
      "Epoch 790, Loss: 140.3014373779297\n",
      "139.75021362304688\n",
      "Epoch 800, Loss: 139.3890838623047\n",
      "138.77340698242188\n",
      "Epoch 810, Loss: 138.49815368652344\n",
      "137.81640625\n",
      "Epoch 820, Loss: 137.61659240722656\n",
      "136.89210510253906\n",
      "Epoch 830, Loss: 136.75924682617188\n",
      "135.99127197265625\n",
      "Epoch 840, Loss: 135.9215087890625\n",
      "135.09864807128906\n",
      "Epoch 850, Loss: 135.10226440429688\n",
      "134.22705078125\n",
      "Epoch 860, Loss: 134.30113220214844\n",
      "133.3907012939453\n",
      "Epoch 870, Loss: 133.51881408691406\n",
      "132.58399963378906\n",
      "Epoch 880, Loss: 132.75689697265625\n",
      "131.79443359375\n",
      "Epoch 890, Loss: 132.0149383544922\n",
      "131.0267791748047\n",
      "Epoch 900, Loss: 131.29315185546875\n",
      "130.27073669433594\n",
      "Epoch 910, Loss: 130.58758544921875\n",
      "129.51870727539062\n",
      "Epoch 920, Loss: 129.89913940429688\n",
      "128.7858428955078\n",
      "Epoch 930, Loss: 129.2194061279297\n",
      "128.06800842285156\n",
      "Epoch 940, Loss: 128.55027770996094\n",
      "127.3610610961914\n",
      "Epoch 950, Loss: 127.89002990722656\n",
      "126.67051696777344\n",
      "Epoch 960, Loss: 127.2404556274414\n",
      "125.98234558105469\n",
      "Epoch 970, Loss: 126.59664154052734\n",
      "125.3118667602539\n",
      "Epoch 980, Loss: 125.9585952758789\n",
      "124.65119171142578\n",
      "Epoch 990, Loss: 125.33238220214844\n",
      "123.99309539794922\n",
      "Epoch 1000, Loss: 124.71585845947266\n",
      "123.34687042236328\n",
      "Epoch 1010, Loss: 124.10467529296875\n",
      "122.71327209472656\n",
      "Epoch 1020, Loss: 123.50553894042969\n",
      "122.0874252319336\n",
      "Epoch 1030, Loss: 122.92272186279297\n",
      "121.46578979492188\n",
      "Epoch 1040, Loss: 122.34844970703125\n",
      "120.86662292480469\n",
      "Epoch 1050, Loss: 121.77953338623047\n",
      "120.28398895263672\n",
      "Epoch 1060, Loss: 121.21040344238281\n",
      "119.70718383789062\n",
      "Epoch 1070, Loss: 120.64347076416016\n",
      "119.11921691894531\n",
      "Epoch 1080, Loss: 120.08467864990234\n",
      "118.5259780883789\n",
      "Epoch 1090, Loss: 119.53208923339844\n",
      "117.94356536865234\n",
      "Epoch 1100, Loss: 118.99340057373047\n",
      "117.3841323852539\n",
      "Epoch 1110, Loss: 118.45223236083984\n",
      "116.83963012695312\n",
      "Epoch 1120, Loss: 117.90211486816406\n",
      "116.3015365600586\n",
      "Epoch 1130, Loss: 117.35030364990234\n",
      "115.75949096679688\n",
      "Epoch 1140, Loss: 116.80641174316406\n",
      "115.2295150756836\n",
      "Epoch 1150, Loss: 116.27711486816406\n",
      "114.71167755126953\n",
      "Epoch 1160, Loss: 115.74812316894531\n",
      "114.21058654785156\n",
      "Epoch 1170, Loss: 115.22514343261719\n",
      "113.71058654785156\n",
      "Epoch 1180, Loss: 114.70838165283203\n",
      "113.21733093261719\n",
      "Epoch 1190, Loss: 114.19960021972656\n",
      "112.73307037353516\n",
      "Epoch 1200, Loss: 113.6987533569336\n",
      "112.26355743408203\n",
      "Epoch 1210, Loss: 113.20840454101562\n",
      "111.79547882080078\n",
      "Epoch 1220, Loss: 112.73182678222656\n",
      "111.34628295898438\n",
      "Epoch 1230, Loss: 112.25955963134766\n",
      "110.90007019042969\n",
      "Epoch 1240, Loss: 111.79259490966797\n",
      "110.44808197021484\n",
      "Epoch 1250, Loss: 111.3313217163086\n",
      "110.00341796875\n",
      "Epoch 1260, Loss: 110.8704833984375\n",
      "109.54812622070312\n",
      "Epoch 1270, Loss: 110.41033935546875\n",
      "109.0753402709961\n",
      "Epoch 1280, Loss: 109.96001434326172\n",
      "108.61722564697266\n",
      "Epoch 1290, Loss: 109.52445220947266\n",
      "108.17205047607422\n",
      "Epoch 1300, Loss: 109.09228515625\n",
      "107.73763275146484\n",
      "Epoch 1310, Loss: 108.65634155273438\n",
      "107.31292724609375\n",
      "Epoch 1320, Loss: 108.22562408447266\n",
      "106.89179992675781\n",
      "Epoch 1330, Loss: 107.8010025024414\n",
      "106.47854614257812\n",
      "Epoch 1340, Loss: 107.3743667602539\n",
      "106.07272338867188\n",
      "Epoch 1350, Loss: 106.96141052246094\n",
      "105.67761993408203\n",
      "Epoch 1360, Loss: 106.5593032836914\n",
      "105.28619384765625\n",
      "Epoch 1370, Loss: 106.16240692138672\n",
      "104.88357543945312\n",
      "Epoch 1380, Loss: 105.7548599243164\n",
      "104.4847183227539\n",
      "Epoch 1390, Loss: 105.35093688964844\n",
      "104.0845718383789\n",
      "Epoch 1400, Loss: 104.94412231445312\n",
      "103.68045043945312\n",
      "Epoch 1410, Loss: 104.54212951660156\n",
      "103.269287109375\n",
      "Epoch 1420, Loss: 104.15074157714844\n",
      "102.87166595458984\n",
      "Epoch 1430, Loss: 103.76970672607422\n",
      "102.48622131347656\n",
      "Epoch 1440, Loss: 103.38947296142578\n",
      "102.10478210449219\n",
      "Epoch 1450, Loss: 103.01333618164062\n",
      "101.73519897460938\n",
      "Epoch 1460, Loss: 102.63763427734375\n",
      "101.35945129394531\n",
      "Epoch 1470, Loss: 102.26453399658203\n",
      "100.9864273071289\n",
      "Epoch 1480, Loss: 101.89684295654297\n",
      "100.62574768066406\n",
      "Epoch 1490, Loss: 101.54212188720703\n",
      "100.2768783569336\n",
      "Epoch 1500, Loss: 101.1931381225586\n",
      "99.92498779296875\n",
      "Epoch 1510, Loss: 100.83656311035156\n",
      "99.5852279663086\n",
      "Epoch 1520, Loss: 100.48336791992188\n",
      "99.25326538085938\n",
      "Epoch 1530, Loss: 100.12770080566406\n",
      "98.92308044433594\n",
      "Epoch 1540, Loss: 99.77105712890625\n",
      "98.59703826904297\n",
      "Epoch 1550, Loss: 99.42254638671875\n",
      "98.27183532714844\n",
      "Epoch 1560, Loss: 99.08366394042969\n",
      "97.94706726074219\n",
      "Epoch 1570, Loss: 98.74751281738281\n",
      "97.62989807128906\n",
      "Epoch 1580, Loss: 98.42091369628906\n",
      "97.31249237060547\n",
      "Epoch 1590, Loss: 98.10175323486328\n",
      "97.0059585571289\n",
      "Epoch 1600, Loss: 97.78448486328125\n",
      "96.7062759399414\n",
      "Epoch 1610, Loss: 97.47509002685547\n",
      "96.39974975585938\n",
      "Epoch 1620, Loss: 97.16814422607422\n",
      "96.10481262207031\n",
      "Epoch 1630, Loss: 96.86355590820312\n",
      "95.80565643310547\n",
      "Epoch 1640, Loss: 96.55319213867188\n",
      "95.51310729980469\n",
      "Epoch 1650, Loss: 96.25167083740234\n",
      "95.2251968383789\n",
      "Epoch 1660, Loss: 95.94987487792969\n",
      "94.95619201660156\n",
      "Epoch 1670, Loss: 95.65570831298828\n",
      "94.6705322265625\n",
      "Epoch 1680, Loss: 95.35769653320312\n",
      "94.40478515625\n",
      "Epoch 1690, Loss: 95.0610122680664\n",
      "94.15474700927734\n",
      "Epoch 1700, Loss: 94.7704086303711\n",
      "93.88630676269531\n",
      "Epoch 1710, Loss: 94.48783874511719\n",
      "93.63275146484375\n",
      "Epoch 1720, Loss: 94.20584869384766\n",
      "93.39493560791016\n",
      "Epoch 1730, Loss: 93.92970275878906\n",
      "93.1344985961914\n",
      "Epoch 1740, Loss: 93.6609878540039\n",
      "92.89617156982422\n",
      "Epoch 1750, Loss: 93.39254760742188\n",
      "92.66365814208984\n",
      "Epoch 1760, Loss: 93.13066101074219\n",
      "92.41787719726562\n",
      "Epoch 1770, Loss: 92.86944580078125\n",
      "92.17015838623047\n",
      "Epoch 1780, Loss: 92.61122131347656\n",
      "91.92876434326172\n",
      "Epoch 1790, Loss: 92.3566665649414\n",
      "91.69092559814453\n",
      "Epoch 1800, Loss: 92.10440826416016\n",
      "91.44783020019531\n",
      "Epoch 1810, Loss: 91.85074615478516\n",
      "91.21565246582031\n",
      "Epoch 1820, Loss: 91.60152435302734\n",
      "90.9878158569336\n",
      "Epoch 1830, Loss: 91.3512954711914\n",
      "90.7651138305664\n",
      "Epoch 1840, Loss: 91.10906982421875\n",
      "90.53376007080078\n",
      "Epoch 1850, Loss: 90.87406158447266\n",
      "90.31880187988281\n",
      "Epoch 1860, Loss: 90.63636016845703\n",
      "90.09730529785156\n",
      "Epoch 1870, Loss: 90.40251922607422\n",
      "89.89278411865234\n",
      "Epoch 1880, Loss: 90.16816711425781\n",
      "89.68792724609375\n",
      "Epoch 1890, Loss: 89.92919158935547\n",
      "89.48810577392578\n",
      "Epoch 1900, Loss: 89.69776916503906\n",
      "89.29640197753906\n",
      "Epoch 1910, Loss: 89.46317291259766\n",
      "89.07218933105469\n",
      "Epoch 1920, Loss: 89.22698974609375\n",
      "88.86125946044922\n",
      "Epoch 1930, Loss: 88.9775619506836\n",
      "88.66242218017578\n",
      "Epoch 1940, Loss: 88.71539306640625\n",
      "88.46066284179688\n",
      "Epoch 1950, Loss: 88.4640884399414\n",
      "88.27213287353516\n",
      "Epoch 1960, Loss: 88.21452331542969\n",
      "88.07156372070312\n",
      "Epoch 1970, Loss: 87.95846557617188\n",
      "87.86619567871094\n",
      "Epoch 1980, Loss: 87.70502471923828\n",
      "87.66554260253906\n",
      "Epoch 1990, Loss: 87.44867706298828\n",
      "87.46820831298828\n",
      "Epoch 2000, Loss: 87.20427703857422\n",
      "87.27920532226562\n",
      "Epoch 2010, Loss: 86.96312713623047\n",
      "87.09186553955078\n",
      "Epoch 2020, Loss: 86.72608184814453\n",
      "86.89408111572266\n",
      "Epoch 2030, Loss: 86.49604797363281\n",
      "86.70148468017578\n",
      "Epoch 2040, Loss: 86.25212860107422\n",
      "86.52068328857422\n",
      "Epoch 2050, Loss: 86.00849914550781\n",
      "86.34842681884766\n",
      "Epoch 2060, Loss: 85.77334594726562\n",
      "86.1704330444336\n",
      "Epoch 2070, Loss: 85.5448226928711\n",
      "85.9912109375\n",
      "Epoch 2080, Loss: 85.32910919189453\n",
      "85.82111358642578\n",
      "Epoch 2090, Loss: 85.11675262451172\n",
      "85.63672637939453\n",
      "Epoch 2100, Loss: 84.91361236572266\n",
      "85.45801544189453\n",
      "Epoch 2110, Loss: 84.71768951416016\n",
      "85.27791595458984\n",
      "Epoch 2120, Loss: 84.52415466308594\n",
      "85.07449340820312\n",
      "Epoch 2130, Loss: 84.3389892578125\n",
      "84.90592193603516\n",
      "Epoch 2140, Loss: 84.15414428710938\n",
      "84.72476959228516\n",
      "Epoch 2150, Loss: 83.97013854980469\n",
      "84.54313659667969\n",
      "Epoch 2160, Loss: 83.7878189086914\n",
      "84.3789291381836\n",
      "Epoch 2170, Loss: 83.60977935791016\n",
      "84.19349670410156\n",
      "Epoch 2180, Loss: 83.43959045410156\n",
      "84.03079223632812\n",
      "Epoch 2190, Loss: 83.26963806152344\n",
      "83.84580993652344\n",
      "Epoch 2200, Loss: 83.10638427734375\n",
      "83.67314910888672\n",
      "Epoch 2210, Loss: 82.9478759765625\n",
      "83.50363159179688\n",
      "Epoch 2220, Loss: 82.79423522949219\n",
      "83.35111236572266\n",
      "Epoch 2230, Loss: 82.64462280273438\n",
      "83.18560791015625\n",
      "Epoch 2240, Loss: 82.49974060058594\n",
      "83.03489685058594\n",
      "Epoch 2250, Loss: 82.3537826538086\n",
      "82.88236236572266\n",
      "Epoch 2260, Loss: 82.19029235839844\n",
      "82.72395324707031\n",
      "Epoch 2270, Loss: 82.00751495361328\n",
      "82.56764221191406\n",
      "Epoch 2280, Loss: 81.81352233886719\n",
      "82.39176940917969\n",
      "Epoch 2290, Loss: 81.66388702392578\n",
      "82.03030395507812\n",
      "Epoch 2300, Loss: 89.64674377441406\n",
      "92.25257110595703\n",
      "Epoch 2310, Loss: 3238.255615234375\n",
      "5944.669921875\n",
      "Epoch 2320, Loss: 776026.3125\n",
      "674696.875\n",
      "Epoch 2330, Loss: 201954.640625\n",
      "85899.0078125\n",
      "Epoch 2340, Loss: 12648.466796875\n",
      "54932.5390625\n",
      "Epoch 2350, Loss: 876.2386474609375\n",
      "8605.107421875\n",
      "Epoch 2360, Loss: 3067.96826171875\n",
      "575.2704467773438\n",
      "Epoch 2370, Loss: 2429.744384765625\n",
      "371.4947204589844\n",
      "Epoch 2380, Loss: 1049.142333984375\n",
      "637.9530639648438\n",
      "Epoch 2390, Loss: 261.47894287109375\n",
      "447.1172180175781\n",
      "Epoch 2400, Loss: 128.8263702392578\n",
      "161.38027954101562\n",
      "Epoch 2410, Loss: 154.24072265625\n",
      "119.40271759033203\n",
      "Epoch 2420, Loss: 127.42733001708984\n",
      "129.7303924560547\n",
      "Epoch 2430, Loss: 114.51348876953125\n",
      "112.31360626220703\n",
      "Epoch 2440, Loss: 113.5118179321289\n",
      "109.5710220336914\n",
      "Epoch 2450, Loss: 109.39269256591797\n",
      "108.04501342773438\n",
      "Epoch 2460, Loss: 107.6186752319336\n",
      "105.81681823730469\n",
      "Epoch 2470, Loss: 105.60579681396484\n",
      "104.02474975585938\n",
      "Epoch 2480, Loss: 104.0376205444336\n",
      "102.64667510986328\n",
      "Epoch 2490, Loss: 102.5688247680664\n",
      "101.42443084716797\n",
      "Epoch 2500, Loss: 101.21648406982422\n",
      "100.28014373779297\n",
      "Epoch 2510, Loss: 99.95624542236328\n",
      "99.18550872802734\n",
      "Epoch 2520, Loss: 98.75911712646484\n",
      "98.17961120605469\n",
      "Epoch 2530, Loss: 97.59691619873047\n",
      "97.240478515625\n",
      "Epoch 2540, Loss: 96.49071502685547\n",
      "96.34161376953125\n",
      "Epoch 2550, Loss: 95.41515350341797\n",
      "95.48649597167969\n",
      "Epoch 2560, Loss: 94.37403869628906\n",
      "94.67412567138672\n",
      "Epoch 2570, Loss: 93.36624145507812\n",
      "93.85842895507812\n",
      "Epoch 2580, Loss: 92.39796447753906\n",
      "93.04864501953125\n",
      "Epoch 2590, Loss: 91.47977447509766\n",
      "92.28424072265625\n",
      "Epoch 2600, Loss: 90.61212158203125\n",
      "91.55840301513672\n",
      "Epoch 2610, Loss: 89.7938003540039\n",
      "90.85066223144531\n",
      "Epoch 2620, Loss: 89.01155090332031\n",
      "90.19278717041016\n",
      "Epoch 2630, Loss: 88.25170135498047\n",
      "89.56122589111328\n",
      "Epoch 2640, Loss: 87.52910614013672\n",
      "88.9495620727539\n",
      "Epoch 2650, Loss: 86.85464477539062\n",
      "88.36270904541016\n",
      "Epoch 2660, Loss: 86.2021255493164\n",
      "87.79900360107422\n",
      "Epoch 2670, Loss: 85.55921173095703\n",
      "87.23792266845703\n",
      "Epoch 2680, Loss: 84.9382095336914\n",
      "86.69165802001953\n",
      "Epoch 2690, Loss: 84.33817291259766\n",
      "86.14651489257812\n",
      "Epoch 2700, Loss: 83.75411224365234\n",
      "85.61787414550781\n",
      "Epoch 2710, Loss: 83.21385955810547\n",
      "85.11479187011719\n",
      "Epoch 2720, Loss: 82.70980072021484\n",
      "84.6388168334961\n",
      "Epoch 2730, Loss: 82.24031066894531\n",
      "84.1993637084961\n",
      "Epoch 2740, Loss: 81.80390167236328\n",
      "83.7809829711914\n",
      "Epoch 2750, Loss: 81.37774658203125\n",
      "83.3740005493164\n",
      "Epoch 2760, Loss: 80.95986938476562\n",
      "82.97560119628906\n",
      "Epoch 2770, Loss: 80.55272674560547\n",
      "82.56442260742188\n",
      "Epoch 2780, Loss: 80.33192443847656\n",
      "82.22489166259766\n",
      "Epoch 2790, Loss: 101.41983032226562\n",
      "115.29571533203125\n",
      "Epoch 2800, Loss: 5223.50244140625\n",
      "9260.900390625\n",
      "Epoch 2810, Loss: 585553.8125\n",
      "425391.4375\n",
      "Epoch 2820, Loss: 145922.609375\n",
      "87857.390625\n",
      "Epoch 2830, Loss: 3249.33349609375\n",
      "12028.494140625\n",
      "Epoch 2840, Loss: 16309.4365234375\n",
      "6303.5205078125\n",
      "Epoch 2850, Loss: 1264.46728515625\n",
      "4771.26318359375\n",
      "Epoch 2860, Loss: 1078.4908447265625\n",
      "159.8695526123047\n",
      "Epoch 2870, Loss: 684.6937866210938\n",
      "730.3887939453125\n",
      "Epoch 2880, Loss: 151.5478973388672\n",
      "161.20254516601562\n",
      "Epoch 2890, Loss: 196.5313262939453\n",
      "173.7919921875\n",
      "Epoch 2900, Loss: 116.13126373291016\n",
      "114.03736114501953\n",
      "Epoch 2910, Loss: 112.47370910644531\n",
      "116.99954223632812\n",
      "Epoch 2920, Loss: 104.78694915771484\n",
      "101.65016174316406\n",
      "Epoch 2930, Loss: 98.37930297851562\n",
      "97.67610168457031\n",
      "Epoch 2940, Loss: 95.81774139404297\n",
      "94.79727172851562\n",
      "Epoch 2950, Loss: 93.32038879394531\n",
      "92.2116470336914\n",
      "Epoch 2960, Loss: 91.2249755859375\n",
      "90.27782440185547\n",
      "Epoch 2970, Loss: 89.58172607421875\n",
      "88.70834350585938\n",
      "Epoch 2980, Loss: 88.18766021728516\n",
      "87.36026000976562\n",
      "Epoch 2990, Loss: 87.00472259521484\n",
      "86.1972885131836\n",
      "Epoch 3000, Loss: 85.98148345947266\n",
      "85.21405792236328\n",
      "Epoch 3010, Loss: 85.07714080810547\n",
      "84.36702728271484\n",
      "Epoch 3020, Loss: 84.28923034667969\n",
      "83.61865997314453\n",
      "Epoch 3030, Loss: 83.59896087646484\n",
      "82.95921325683594\n",
      "Epoch 3040, Loss: 82.97642517089844\n",
      "82.35106658935547\n",
      "Epoch 3050, Loss: 82.423583984375\n",
      "81.81012725830078\n",
      "Epoch 3060, Loss: 81.9166030883789\n",
      "81.32166290283203\n",
      "Epoch 3070, Loss: 81.4289779663086\n",
      "80.89007568359375\n",
      "Epoch 3080, Loss: 80.96112823486328\n",
      "80.4924087524414\n",
      "Epoch 3090, Loss: 80.52974700927734\n",
      "80.11361694335938\n",
      "Epoch 3100, Loss: 80.1353530883789\n",
      "79.77012634277344\n",
      "Epoch 3110, Loss: 79.73693084716797\n",
      "79.44229125976562\n",
      "Epoch 3120, Loss: 79.35610961914062\n",
      "79.12450408935547\n",
      "Epoch 3130, Loss: 78.99019622802734\n",
      "78.78933715820312\n",
      "Epoch 3140, Loss: 78.64030456542969\n",
      "78.45954132080078\n",
      "Epoch 3150, Loss: 78.30931854248047\n",
      "78.14988708496094\n",
      "Epoch 3160, Loss: 77.99787902832031\n",
      "77.8674545288086\n",
      "Epoch 3170, Loss: 77.70934295654297\n",
      "77.62496185302734\n",
      "Epoch 3180, Loss: 77.44237518310547\n",
      "77.40531158447266\n",
      "Epoch 3190, Loss: 77.19087982177734\n",
      "77.18926239013672\n",
      "Epoch 3200, Loss: 76.95278930664062\n",
      "76.96610260009766\n",
      "Epoch 3210, Loss: 76.73704528808594\n",
      "76.7245864868164\n",
      "Epoch 3220, Loss: 77.39051818847656\n",
      "77.42243957519531\n",
      "Epoch 3230, Loss: 184.91673278808594\n",
      "253.35289001464844\n",
      "Epoch 3240, Loss: 25696.931640625\n",
      "45220.85546875\n",
      "Epoch 3250, Loss: 14393.3857421875\n",
      "35871.62109375\n",
      "Epoch 3260, Loss: 2225.173828125\n",
      "49264.3125\n",
      "Epoch 3270, Loss: 29920.259765625\n",
      "15258.9306640625\n",
      "Epoch 3280, Loss: 163.13900756835938\n",
      "5113.82373046875\n",
      "Epoch 3290, Loss: 3625.053466796875\n",
      "1141.2342529296875\n",
      "Epoch 3300, Loss: 182.7431182861328\n",
      "989.2542114257812\n",
      "Epoch 3310, Loss: 537.2078857421875\n",
      "246.0347900390625\n",
      "Epoch 3320, Loss: 100.14146423339844\n",
      "169.06398010253906\n",
      "Epoch 3330, Loss: 149.640869140625\n",
      "131.3548583984375\n",
      "Epoch 3340, Loss: 99.96924591064453\n",
      "95.46408081054688\n",
      "Epoch 3350, Loss: 90.93045043945312\n",
      "99.2929916381836\n",
      "Epoch 3360, Loss: 90.04686737060547\n",
      "93.05467224121094\n",
      "Epoch 3370, Loss: 86.61678314208984\n",
      "88.40647888183594\n",
      "Epoch 3380, Loss: 84.37989044189453\n",
      "86.16069030761719\n",
      "Epoch 3390, Loss: 82.989501953125\n",
      "84.61027526855469\n",
      "Epoch 3400, Loss: 81.88582611083984\n",
      "83.34393310546875\n",
      "Epoch 3410, Loss: 80.94490051269531\n",
      "82.27008819580078\n",
      "Epoch 3420, Loss: 80.14350891113281\n",
      "81.35197448730469\n",
      "Epoch 3430, Loss: 79.44196319580078\n",
      "80.54967498779297\n",
      "Epoch 3440, Loss: 78.79878234863281\n",
      "79.7940673828125\n",
      "Epoch 3450, Loss: 78.222900390625\n",
      "79.09630584716797\n",
      "Epoch 3460, Loss: 77.70166778564453\n",
      "78.4626235961914\n",
      "Epoch 3470, Loss: 77.23703002929688\n",
      "77.88487243652344\n",
      "Epoch 3480, Loss: 76.80514526367188\n",
      "77.35609436035156\n",
      "Epoch 3490, Loss: 76.39368438720703\n",
      "76.86911010742188\n",
      "Epoch 3500, Loss: 76.01216125488281\n",
      "76.41371154785156\n",
      "Epoch 3510, Loss: 75.65918731689453\n",
      "75.9890365600586\n",
      "Epoch 3520, Loss: 75.332275390625\n",
      "75.5746841430664\n",
      "Epoch 3530, Loss: 75.01847076416016\n",
      "75.20176696777344\n",
      "Epoch 3540, Loss: 74.72285461425781\n",
      "74.85060119628906\n",
      "Epoch 3550, Loss: 74.44300079345703\n",
      "74.52375793457031\n",
      "Epoch 3560, Loss: 74.1768569946289\n",
      "74.2274169921875\n",
      "Epoch 3570, Loss: 73.92317199707031\n",
      "73.92415618896484\n",
      "Epoch 3580, Loss: 73.68177032470703\n",
      "73.66539001464844\n",
      "Epoch 3590, Loss: 73.45690155029297\n",
      "73.41348266601562\n",
      "Epoch 3600, Loss: 73.24384307861328\n",
      "73.18325805664062\n",
      "Epoch 3610, Loss: 73.03999328613281\n",
      "72.96612548828125\n",
      "Epoch 3620, Loss: 72.8434829711914\n",
      "72.75643157958984\n",
      "Epoch 3630, Loss: 72.65591430664062\n",
      "72.53116607666016\n",
      "Epoch 3640, Loss: 72.47894287109375\n",
      "72.24996185302734\n",
      "Epoch 3650, Loss: 73.12034606933594\n",
      "72.55290985107422\n",
      "Epoch 3660, Loss: 218.54722595214844\n",
      "314.98388671875\n",
      "Epoch 3670, Loss: 47271.74609375\n",
      "84402.6796875\n",
      "Epoch 3680, Loss: 92456.734375\n",
      "216768.03125\n",
      "Epoch 3690, Loss: 79788.8515625\n",
      "43552.55859375\n",
      "Epoch 3700, Loss: 437.8817443847656\n",
      "15107.3564453125\n",
      "Epoch 3710, Loss: 6840.81005859375\n",
      "428.9100036621094\n",
      "Epoch 3720, Loss: 2509.01025390625\n",
      "2916.294677734375\n",
      "Epoch 3730, Loss: 139.18496704101562\n",
      "516.4938354492188\n",
      "Epoch 3740, Loss: 498.4021301269531\n",
      "201.3385772705078\n",
      "Epoch 3750, Loss: 125.27691650390625\n",
      "238.06565856933594\n",
      "Epoch 3760, Loss: 138.28515625\n",
      "110.13188171386719\n",
      "Epoch 3770, Loss: 96.43730926513672\n",
      "106.52100372314453\n",
      "Epoch 3780, Loss: 96.15958404541016\n",
      "94.31124877929688\n",
      "Epoch 3790, Loss: 87.42865753173828\n",
      "93.41881561279297\n",
      "Epoch 3800, Loss: 85.83300018310547\n",
      "91.07606506347656\n",
      "Epoch 3810, Loss: 83.72805786132812\n",
      "87.77912902832031\n",
      "Epoch 3820, Loss: 82.01703643798828\n",
      "85.8265609741211\n",
      "Epoch 3830, Loss: 80.72119903564453\n",
      "84.47135925292969\n",
      "Epoch 3840, Loss: 79.57635498046875\n",
      "83.32810974121094\n",
      "Epoch 3850, Loss: 78.55472564697266\n",
      "82.33080291748047\n",
      "Epoch 3860, Loss: 77.64057159423828\n",
      "81.41903686523438\n",
      "Epoch 3870, Loss: 76.82019805908203\n",
      "80.59500885009766\n",
      "Epoch 3880, Loss: 76.08409118652344\n",
      "79.827392578125\n",
      "Epoch 3890, Loss: 75.41170501708984\n",
      "79.11992645263672\n",
      "Epoch 3900, Loss: 74.79222106933594\n",
      "78.4625015258789\n",
      "Epoch 3910, Loss: 74.22476959228516\n",
      "77.838623046875\n",
      "Epoch 3920, Loss: 73.70255279541016\n",
      "77.25249481201172\n",
      "Epoch 3930, Loss: 73.2261962890625\n",
      "76.70366668701172\n",
      "Epoch 3940, Loss: 72.78839874267578\n",
      "76.1977767944336\n",
      "Epoch 3950, Loss: 72.37602233886719\n",
      "75.71914672851562\n",
      "Epoch 3960, Loss: 71.98954010009766\n",
      "75.27022552490234\n",
      "Epoch 3970, Loss: 71.6361083984375\n",
      "74.85865783691406\n",
      "Epoch 3980, Loss: 71.30455017089844\n",
      "74.47093200683594\n",
      "Epoch 3990, Loss: 70.99718475341797\n",
      "74.10281372070312\n",
      "Epoch 4000, Loss: 70.70761108398438\n",
      "73.7569580078125\n",
      "Epoch 4010, Loss: 70.4341812133789\n",
      "73.42362213134766\n",
      "Epoch 4020, Loss: 70.17515563964844\n",
      "73.1142807006836\n",
      "Epoch 4030, Loss: 69.92434692382812\n",
      "72.80860137939453\n",
      "Epoch 4040, Loss: 69.68754577636719\n",
      "72.514404296875\n",
      "Epoch 4050, Loss: 69.46336364746094\n",
      "72.23477172851562\n",
      "Epoch 4060, Loss: 69.25626373291016\n",
      "71.96218872070312\n",
      "Epoch 4070, Loss: 69.05626678466797\n",
      "71.69828796386719\n",
      "Epoch 4080, Loss: 68.86287689208984\n",
      "71.44287872314453\n",
      "Epoch 4090, Loss: 68.6843032836914\n",
      "71.20258331298828\n",
      "Epoch 4100, Loss: 68.51797485351562\n",
      "70.93763732910156\n",
      "Epoch 4110, Loss: 68.93052673339844\n",
      "71.20460510253906\n",
      "Epoch 4120, Loss: 185.45245361328125\n",
      "270.0368957519531\n",
      "Epoch 4130, Loss: 42481.78125\n",
      "76767.0625\n",
      "Epoch 4140, Loss: 96155.9765625\n",
      "211672.34375\n",
      "Epoch 4150, Loss: 76154.65625\n",
      "29796.6171875\n",
      "Epoch 4160, Loss: 4027.712890625\n",
      "20267.08203125\n",
      "Epoch 4170, Loss: 2516.155517578125\n",
      "906.9224243164062\n",
      "Epoch 4180, Loss: 3136.62841796875\n",
      "1110.9498291015625\n",
      "Epoch 4190, Loss: 573.85546875\n",
      "1021.0318603515625\n",
      "Epoch 4200, Loss: 157.57015991210938\n",
      "195.6239776611328\n",
      "Epoch 4210, Loss: 235.1396484375\n",
      "168.44361877441406\n",
      "Epoch 4220, Loss: 98.63058471679688\n",
      "118.68579864501953\n",
      "Epoch 4230, Loss: 104.26119995117188\n",
      "90.4166488647461\n",
      "Epoch 4240, Loss: 88.42894744873047\n",
      "96.52699279785156\n",
      "Epoch 4250, Loss: 87.03450775146484\n",
      "87.35037994384766\n",
      "Epoch 4260, Loss: 83.51705932617188\n",
      "83.75335693359375\n",
      "Epoch 4270, Loss: 82.45791625976562\n",
      "82.6843032836914\n",
      "Epoch 4280, Loss: 81.1707763671875\n",
      "82.16624450683594\n",
      "Epoch 4290, Loss: 80.17539978027344\n",
      "81.51264953613281\n",
      "Epoch 4300, Loss: 79.35176086425781\n",
      "80.65813446044922\n",
      "Epoch 4310, Loss: 78.60011291503906\n",
      "79.81327056884766\n",
      "Epoch 4320, Loss: 77.92715454101562\n",
      "79.0791015625\n",
      "Epoch 4330, Loss: 77.33001708984375\n",
      "78.418701171875\n",
      "Epoch 4340, Loss: 76.79438018798828\n",
      "77.81661224365234\n",
      "Epoch 4350, Loss: 76.31307983398438\n",
      "77.2742691040039\n",
      "Epoch 4360, Loss: 75.86544799804688\n",
      "76.76383209228516\n",
      "Epoch 4370, Loss: 75.43759155273438\n",
      "76.274169921875\n",
      "Epoch 4380, Loss: 75.02354431152344\n",
      "75.8111572265625\n",
      "Epoch 4390, Loss: 74.63097381591797\n",
      "75.3875503540039\n",
      "Epoch 4400, Loss: 74.26272583007812\n",
      "74.97905731201172\n",
      "Epoch 4410, Loss: 73.92301940917969\n",
      "74.60591125488281\n",
      "Epoch 4420, Loss: 73.60176086425781\n",
      "74.25653076171875\n",
      "Epoch 4430, Loss: 73.2967529296875\n",
      "73.92092895507812\n",
      "Epoch 4440, Loss: 73.0185775756836\n",
      "73.60089111328125\n",
      "Epoch 4450, Loss: 72.75645446777344\n",
      "73.26359558105469\n",
      "Epoch 4460, Loss: 72.50687408447266\n",
      "72.94923400878906\n",
      "Epoch 4470, Loss: 72.2647476196289\n",
      "72.65314483642578\n",
      "Epoch 4480, Loss: 72.03237915039062\n",
      "72.36138916015625\n",
      "Epoch 4490, Loss: 71.8125991821289\n",
      "72.08264923095703\n",
      "Epoch 4500, Loss: 71.60453033447266\n",
      "71.82392120361328\n",
      "Epoch 4510, Loss: 71.40811157226562\n",
      "71.57420349121094\n",
      "Epoch 4520, Loss: 71.21946716308594\n",
      "71.3340835571289\n",
      "Epoch 4530, Loss: 71.04217529296875\n",
      "71.11058807373047\n",
      "Epoch 4540, Loss: 70.87344360351562\n",
      "70.89617156982422\n",
      "Epoch 4550, Loss: 70.71162414550781\n",
      "70.69707489013672\n",
      "Epoch 4560, Loss: 70.5636978149414\n",
      "70.57791137695312\n",
      "Epoch 4570, Loss: 70.54295349121094\n",
      "70.98574829101562\n",
      "Epoch 4580, Loss: 76.35282897949219\n",
      "83.40039825439453\n",
      "Epoch 4590, Loss: 693.6806640625\n",
      "1144.3817138671875\n",
      "Epoch 4600, Loss: 106953.0234375\n",
      "167266.890625\n",
      "Epoch 4610, Loss: 131876.578125\n",
      "86443.28125\n",
      "Epoch 4620, Loss: 37679.04296875\n",
      "11206.173828125\n",
      "Epoch 4630, Loss: 1565.4000244140625\n",
      "2181.22607421875\n",
      "Epoch 4640, Loss: 2558.59326171875\n",
      "4527.4130859375\n",
      "Epoch 4650, Loss: 1618.1229248046875\n",
      "515.063232421875\n",
      "Epoch 4660, Loss: 137.4415283203125\n",
      "196.64739990234375\n",
      "Epoch 4670, Loss: 165.67018127441406\n",
      "250.8280487060547\n",
      "Epoch 4680, Loss: 157.82032775878906\n",
      "127.69245910644531\n",
      "Epoch 4690, Loss: 105.05332946777344\n",
      "83.85398864746094\n",
      "Epoch 4700, Loss: 84.03185272216797\n",
      "78.71607971191406\n",
      "Epoch 4710, Loss: 78.77169036865234\n",
      "78.13687133789062\n",
      "Epoch 4720, Loss: 77.24340057373047\n",
      "77.2507553100586\n",
      "Epoch 4730, Loss: 76.47727966308594\n",
      "76.40205383300781\n",
      "Epoch 4740, Loss: 75.92168426513672\n",
      "75.72358703613281\n",
      "Epoch 4750, Loss: 75.45861053466797\n",
      "75.20134735107422\n",
      "Epoch 4760, Loss: 75.04174041748047\n",
      "74.75416564941406\n",
      "Epoch 4770, Loss: 74.67171478271484\n",
      "74.39020538330078\n",
      "Epoch 4780, Loss: 74.33418273925781\n",
      "74.08024597167969\n",
      "Epoch 4790, Loss: 74.01886749267578\n",
      "73.77156829833984\n",
      "Epoch 4800, Loss: 73.72530364990234\n",
      "73.45248413085938\n",
      "Epoch 4810, Loss: 73.46003723144531\n",
      "73.14572143554688\n",
      "Epoch 4820, Loss: 73.21117401123047\n",
      "72.85926818847656\n",
      "Epoch 4830, Loss: 72.98033905029297\n",
      "72.59165954589844\n",
      "Epoch 4840, Loss: 72.76758575439453\n",
      "72.32841491699219\n",
      "Epoch 4850, Loss: 72.56515502929688\n",
      "72.07444763183594\n",
      "Epoch 4860, Loss: 72.37846374511719\n",
      "71.83680725097656\n",
      "Epoch 4870, Loss: 72.19937896728516\n",
      "71.61075592041016\n",
      "Epoch 4880, Loss: 72.02066802978516\n",
      "71.39269256591797\n",
      "Epoch 4890, Loss: 71.84513854980469\n",
      "71.17870330810547\n",
      "Epoch 4900, Loss: 71.67591857910156\n",
      "70.97931671142578\n",
      "Epoch 4910, Loss: 71.510986328125\n",
      "70.80081176757812\n",
      "Epoch 4920, Loss: 71.35096740722656\n",
      "70.62958526611328\n",
      "Epoch 4930, Loss: 71.19467163085938\n",
      "70.46418762207031\n",
      "Epoch 4940, Loss: 71.0447769165039\n",
      "70.29743194580078\n",
      "Epoch 4950, Loss: 70.8985595703125\n",
      "70.1015625\n",
      "Epoch 4960, Loss: 70.9044418334961\n",
      "69.81009674072266\n",
      "Epoch 4970, Loss: 91.29139709472656\n",
      "99.90592193603516\n",
      "Epoch 4980, Loss: 5510.85791015625\n",
      "9787.7216796875\n",
      "Epoch 4990, Loss: 296574.71875\n",
      "120198.25\n"
     ]
    }
   ],
   "source": [
    "def evaluate_mlp(model, features, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(features)\n",
    "        mse = F.mse_loss(predictions.squeeze(), labels)\n",
    "    return mse.item()\n",
    "\n",
    "def train_mlp(model, features, labels, test_features, test_labels, epochs=100, learning_rate=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "            print(evaluate_mlp(mlp_model, test_features, test_labels))\n",
    "\n",
    "# Prepare data\n",
    "features = final_train.x\n",
    "labels = final_train.y.float()\n",
    "\n",
    "# Initialize and train the MLP\n",
    "test_features = final_test.x.to(device)\n",
    "test_labels = final_test.y.float().to(device)\n",
    "mlp_model = MLP(input_dim=features.shape[1], hidden_dim=100, output_dim=1).to(device)\n",
    "train_mlp(mlp_model, features.to(device), labels.to(device), test_features.to(device), test_labels.to(device), epochs=5000, learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e32fdbbd-1488-4598-a9d7-b5e1c00bdf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Test MSE: 64552.5390625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate MLP\n",
    "mlp_test_mse = evaluate_mlp(mlp_model, test_features, test_labels)\n",
    "\n",
    "print(f'MLP Test MSE: {mlp_test_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2014165e-8b30-44c4-97df-57791d5237b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Loss: 685.69\n",
      "Epoch  10 | Loss: 111.48\n",
      "Epoch  20 | Loss: 44.85\n",
      "Epoch  30 | Loss: 29.47\n",
      "Epoch  40 | Loss: 26.60\n",
      "Epoch  50 | Loss: 22.21\n",
      "Epoch  60 | Loss: 21.04\n",
      "Epoch  70 | Loss: 20.86\n",
      "Epoch  80 | Loss: 20.49\n",
      "Epoch  90 | Loss: 20.93\n",
      "Epoch 100 | Loss: 18.55\n",
      "Epoch 110 | Loss: 18.71\n",
      "Epoch 120 | Loss: 18.36\n",
      "Epoch 130 | Loss: 17.69\n",
      "Epoch 140 | Loss: 17.77\n",
      "Epoch 150 | Loss: 17.03\n",
      "Epoch 160 | Loss: 17.84\n",
      "Epoch 170 | Loss: 16.56\n",
      "Epoch 180 | Loss: 17.19\n",
      "Epoch 190 | Loss: 17.24\n",
      "36.4619026184082\n"
     ]
    }
   ],
   "source": [
    "three_layer_model = GCN(num_features=final_train.x.shape[1], num_hidden_layers=2, hidden_channels=768).to(device)\n",
    "train(three_layer_model, final_train)\n",
    "print(test_mse(three_layer_model, final_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "108fb976-5d4f-47a9-83ff-f31572a795f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Loss: 673.03\n",
      "Epoch  10 | Loss: 82.04\n",
      "Epoch  20 | Loss: 30.03\n",
      "Epoch  30 | Loss: 22.37\n",
      "Epoch  40 | Loss: 21.19\n",
      "Epoch  50 | Loss: 18.74\n",
      "Epoch  60 | Loss: 17.05\n",
      "Epoch  70 | Loss: 17.66\n",
      "Epoch  80 | Loss: 17.51\n",
      "Epoch  90 | Loss: 16.63\n",
      "Epoch 100 | Loss: 16.34\n",
      "Epoch 110 | Loss: 15.61\n",
      "Epoch 120 | Loss: 15.44\n",
      "Epoch 130 | Loss: 15.41\n",
      "Epoch 140 | Loss: 15.17\n",
      "Epoch 150 | Loss: 15.00\n",
      "Epoch 160 | Loss: 15.27\n",
      "Epoch 170 | Loss: 14.89\n",
      "Epoch 180 | Loss: 15.17\n",
      "Epoch 190 | Loss: 14.41\n",
      "41.53360366821289\n"
     ]
    }
   ],
   "source": [
    "three_layer_model = GCN(num_features=final_train.x.shape[1], num_hidden_layers=4, hidden_channels=768).to(device)\n",
    "train(three_layer_model, final_train)\n",
    "print(test_mse(three_layer_model, final_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a655a4f4-2f81-480f-86b5-bbd47dbf20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model_pytorch(data):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Automatically choose the device\n",
    "    data = data.to(device)  # Ensure the data is on the correct device\n",
    "    train_mean = data.y.float().mean()  # Calculate mean over all data.y\n",
    "    baseline_predictions = torch.full_like(data.y, train_mean, device=device)  # Ensure this tensor is on GPU\n",
    "    mse = F.mse_loss(baseline_predictions, data.y.float())  # Calculate MSE over all data.y\n",
    "    return mse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fedcf919-7a16-411e-b94f-d12716d4ff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Training MSE: 20.35999870300293\n",
      "Baseline Test MSE: 20.62066650390625\n"
     ]
    }
   ],
   "source": [
    "train_mse_baseline = baseline_model_pytorch(final_train)\n",
    "test_mse_baseline = baseline_model_pytorch(final_test)\n",
    "\n",
    "print(f\"Baseline Training MSE: {train_mse_baseline}\")\n",
    "print(f\"Baseline Test MSE: {test_mse_baseline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eab16f-69f0-4d85-aad1-c1b122d45304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
